apiVersion: sedna.io/v1alpha1
kind:  Model
metadata:
  name: helmet-detection-inference-big-model
  namespace: default
spec:
  url: "/data/big-model/yolov3_darknet.pb"
  format: "pb"
---
apiVersion: sedna.io/v1alpha1
kind: Model
metadata:
  name: helmet-detection-inference-little-model
  namespace: default
spec:
  url: "/data/little-model/yolov3_resnet18.pb"
  format: "pb"
---
apiVersion: sedna.io/v1alpha1
kind: JointInferenceService
metadata:
  name: helmet-detection-inference-example
  namespace: default
spec:
  edgeWorker:
    model:
      name: "helmet-detection-inference-little-model"
    hardExampleMining:
      name: "IBT"
      parameters:
        - key: "threshold_img"
          value: "0.9"
        - key: "threshold_box"
          value: "0.9"
    template:
      spec:
        nodeName: chengfei-edge01
        dnsPolicy: ClusterFirstWithHostNet
        containers:
          - image: poorunga/sedna-example-joint-inference-helmet-detection-little-arm64:v0.3.1
            imagePullPolicy: IfNotPresent
            name: little-model
            env: # user defined environments
              - name: input_shape
                value: "416,736"
              - name: "video_url"
                value: "rtsp://localhost/video"
              - name: "all_examples_inference_output"
                value: "/data/output"
              - name: "hard_example_cloud_inference_output"
                value: "/data/hard_example_cloud_inference_output"
              - name: "hard_example_edge_inference_output"
                value: "/data/hard_example_edge_inference_output"
              - name: "SUPER_BIG_MODEL_IP"
                value: "192.168.0.196"
              - name: "INFERENCE_TIMEOUT"
                value: "3699"
            resources: # user defined resources
              requests:
                memory: 64M
                cpu: 100m
              limits:
                memory: 2Gi
            volumeMounts:
              - name: outputdir
                mountPath: /data/
        volumes: # user defined volumes
          - name: outputdir
            hostPath:
              # user must create the directory in host
              path: /joint_inference/output
              type: Directory

  cloudWorker:
    model:
      name: "helmet-detection-inference-big-model"
    template:
      spec:
        nodeName: chengfei-node1
        hostNetwork: true
        containers:
          - image: poorunga/sedna-example-joint-inference-helmet-detection-big-arm64:v0.3.1
            name: big-model
            imagePullPolicy: IfNotPresent
            env: # user defined environments
              - name: "input_shape"
                value: "544,544"
            resources: # user defined resources
              requests:
                memory: 2Gi
            volumeMounts:
              - mountPath: /data
                name: data
        volumes:
        - name: data
          hostPath:
            path: /data
            type: Directory
